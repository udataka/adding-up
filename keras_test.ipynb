{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/udataka/adding-up/blob/master/keras_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "EKvSZ8UYUs9o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1295
        },
        "outputId": "5ea2581a-4c4b-45b3-c72f-114442e6b3a3"
      },
      "cell_type": "code",
      "source": [
        "'''Trains a simple deep NN on the MNIST dataset.\n",
        "Gets to 98.40% test accuracy after 20 epochs\n",
        "(there is *a lot* of margin for parameter tuning).\n",
        "2 seconds per epoch on a K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.2461 - acc: 0.9233 - val_loss: 0.1139 - val_acc: 0.9634\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.1022 - acc: 0.9681 - val_loss: 0.0876 - val_acc: 0.9742\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.0743 - acc: 0.9774 - val_loss: 0.0794 - val_acc: 0.9775\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0605 - acc: 0.9816 - val_loss: 0.0727 - val_acc: 0.9795\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0486 - acc: 0.9855 - val_loss: 0.0918 - val_acc: 0.9784\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0425 - acc: 0.9875 - val_loss: 0.0911 - val_acc: 0.9797\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.0383 - acc: 0.9884 - val_loss: 0.0827 - val_acc: 0.9822\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0346 - acc: 0.9902 - val_loss: 0.1004 - val_acc: 0.9790\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0328 - acc: 0.9909 - val_loss: 0.0812 - val_acc: 0.9836\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.0283 - acc: 0.9920 - val_loss: 0.1040 - val_acc: 0.9790\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.0284 - acc: 0.9920 - val_loss: 0.0931 - val_acc: 0.9817\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.0273 - acc: 0.9925 - val_loss: 0.1060 - val_acc: 0.9809\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0231 - acc: 0.9934 - val_loss: 0.0966 - val_acc: 0.9816\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0228 - acc: 0.9933 - val_loss: 0.1088 - val_acc: 0.9814\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.0235 - acc: 0.9939 - val_loss: 0.0962 - val_acc: 0.9836\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0211 - acc: 0.9943 - val_loss: 0.0961 - val_acc: 0.9839\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0172 - acc: 0.9952 - val_loss: 0.0950 - val_acc: 0.9851\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0191 - acc: 0.9948 - val_loss: 0.1108 - val_acc: 0.9828\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0187 - acc: 0.9953 - val_loss: 0.1008 - val_acc: 0.9847\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.0159 - acc: 0.9956 - val_loss: 0.1184 - val_acc: 0.9821\n",
            "Test loss: 0.11843686554676497\n",
            "Test accuracy: 0.9821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7Hunlb62U-hB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CvWAMrbWV6h_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "時間をはかると"
      ]
    },
    {
      "metadata": {
        "id": "vvf5hPgqV_df",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        },
        "outputId": "6b4e54a4-a345-4026-81b2-6d71f3bfe750"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "'''Trains a simple deep NN on the MNIST dataset.\n",
        "Gets to 98.40% test accuracy after 20 epochs\n",
        "(there is *a lot* of margin for parameter tuning).\n",
        "2 seconds per epoch on a K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 11s 181us/step - loss: 0.2456 - acc: 0.9246 - val_loss: 0.1376 - val_acc: 0.9573\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 11s 182us/step - loss: 0.1029 - acc: 0.9690 - val_loss: 0.0920 - val_acc: 0.9710\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.0755 - acc: 0.9771 - val_loss: 0.0733 - val_acc: 0.9782\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.0612 - acc: 0.9819 - val_loss: 0.0813 - val_acc: 0.9781\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.0515 - acc: 0.9846 - val_loss: 0.0828 - val_acc: 0.9775\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0434 - acc: 0.9869 - val_loss: 0.0887 - val_acc: 0.9774\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0368 - acc: 0.9891 - val_loss: 0.0849 - val_acc: 0.9822\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0363 - acc: 0.9898 - val_loss: 0.0850 - val_acc: 0.9828\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0329 - acc: 0.9903 - val_loss: 0.0838 - val_acc: 0.9813\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0274 - acc: 0.9926 - val_loss: 0.0973 - val_acc: 0.9826\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.0263 - acc: 0.9923 - val_loss: 0.1002 - val_acc: 0.9824\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 10s 175us/step - loss: 0.0234 - acc: 0.9931 - val_loss: 0.0972 - val_acc: 0.9828\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0238 - acc: 0.9933 - val_loss: 0.1001 - val_acc: 0.9803\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0220 - acc: 0.9936 - val_loss: 0.1038 - val_acc: 0.9822\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.0204 - acc: 0.9942 - val_loss: 0.1021 - val_acc: 0.9826\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0202 - acc: 0.9942 - val_loss: 0.1085 - val_acc: 0.9822\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0214 - acc: 0.9946 - val_loss: 0.1023 - val_acc: 0.9834\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.0190 - acc: 0.9950 - val_loss: 0.1094 - val_acc: 0.9839\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0192 - acc: 0.9951 - val_loss: 0.0959 - val_acc: 0.9852\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 11s 175us/step - loss: 0.0188 - acc: 0.9954 - val_loss: 0.1185 - val_acc: 0.9826\n",
            "Test loss: 0.11847384011999439\n",
            "Test accuracy: 0.9826\n",
            "CPU times: user 5min 54s, sys: 17.5 s, total: 6min 12s\n",
            "Wall time: 3min 34s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KziEdAlRWFpu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "756Evc_7XR93",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rEtV3sGrXTJ4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "GPUあり"
      ]
    },
    {
      "metadata": {
        "id": "yXIemSB3XV5v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1329
        },
        "outputId": "3dc15efc-0788-4f1b-8444-68859d8cb35f"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "'''Trains a simple deep NN on the MNIST dataset.\n",
        "Gets to 98.40% test accuracy after 20 epochs\n",
        "(there is *a lot* of margin for parameter tuning).\n",
        "2 seconds per epoch on a K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.2471 - acc: 0.9231 - val_loss: 0.1213 - val_acc: 0.9617\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.1040 - acc: 0.9681 - val_loss: 0.0906 - val_acc: 0.9709\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0751 - acc: 0.9773 - val_loss: 0.0789 - val_acc: 0.9766\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 0.0624 - acc: 0.9814 - val_loss: 0.0804 - val_acc: 0.9757\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0493 - acc: 0.9855 - val_loss: 0.0692 - val_acc: 0.9823\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0441 - acc: 0.9862 - val_loss: 0.0728 - val_acc: 0.9823\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 3s 50us/step - loss: 0.0393 - acc: 0.9886 - val_loss: 0.0794 - val_acc: 0.9809\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0377 - acc: 0.9889 - val_loss: 0.0856 - val_acc: 0.9808\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.0302 - acc: 0.9911 - val_loss: 0.0883 - val_acc: 0.9817\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.0288 - acc: 0.9919 - val_loss: 0.0876 - val_acc: 0.9824\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.0275 - acc: 0.9922 - val_loss: 0.0837 - val_acc: 0.9836\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.0242 - acc: 0.9933 - val_loss: 0.0983 - val_acc: 0.9822\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 3s 50us/step - loss: 0.0240 - acc: 0.9932 - val_loss: 0.1220 - val_acc: 0.9782\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0229 - acc: 0.9937 - val_loss: 0.0976 - val_acc: 0.9827\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0232 - acc: 0.9939 - val_loss: 0.1008 - val_acc: 0.9832\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.0206 - acc: 0.9943 - val_loss: 0.1026 - val_acc: 0.9821\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 0.0209 - acc: 0.9946 - val_loss: 0.1144 - val_acc: 0.9805\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.0189 - acc: 0.9949 - val_loss: 0.1202 - val_acc: 0.9822\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.0183 - acc: 0.9953 - val_loss: 0.1191 - val_acc: 0.9847\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 0.0178 - acc: 0.9955 - val_loss: 0.1075 - val_acc: 0.9832\n",
            "Test loss: 0.10748489045228189\n",
            "Test accuracy: 0.9832\n",
            "CPU times: user 1min 10s, sys: 10.4 s, total: 1min 21s\n",
            "Wall time: 1min 8s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vkuo-TudX17J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TPU使用\n"
      ]
    },
    {
      "metadata": {
        "id": "zlWCj5XUX5Ew",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1329
        },
        "outputId": "668985ac-8bb2-45b2-f11b-090af2ec0d03"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "'''Trains a simple deep NN on the MNIST dataset.\n",
        "Gets to 98.40% test accuracy after 20 epochs\n",
        "(there is *a lot* of margin for parameter tuning).\n",
        "2 seconds per epoch on a K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.2446 - acc: 0.9250 - val_loss: 0.1208 - val_acc: 0.9615\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.1025 - acc: 0.9693 - val_loss: 0.0732 - val_acc: 0.9779\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.0756 - acc: 0.9776 - val_loss: 0.0857 - val_acc: 0.9748\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 10s 165us/step - loss: 0.0606 - acc: 0.9813 - val_loss: 0.0683 - val_acc: 0.9815\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.0510 - acc: 0.9847 - val_loss: 0.0725 - val_acc: 0.9812\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.0437 - acc: 0.9873 - val_loss: 0.0824 - val_acc: 0.9797\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 10s 163us/step - loss: 0.0394 - acc: 0.9885 - val_loss: 0.0826 - val_acc: 0.9786\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 10s 164us/step - loss: 0.0333 - acc: 0.9902 - val_loss: 0.0859 - val_acc: 0.9819\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 10s 164us/step - loss: 0.0319 - acc: 0.9908 - val_loss: 0.0813 - val_acc: 0.9827\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 10s 163us/step - loss: 0.0293 - acc: 0.9915 - val_loss: 0.0932 - val_acc: 0.9808\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.0268 - acc: 0.9925 - val_loss: 0.0999 - val_acc: 0.9809\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.0271 - acc: 0.9925 - val_loss: 0.0931 - val_acc: 0.9821\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 10s 165us/step - loss: 0.0254 - acc: 0.9931 - val_loss: 0.0983 - val_acc: 0.9815\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 10s 164us/step - loss: 0.0239 - acc: 0.9937 - val_loss: 0.0987 - val_acc: 0.9825\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 10s 164us/step - loss: 0.0217 - acc: 0.9944 - val_loss: 0.0967 - val_acc: 0.9835\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 10s 165us/step - loss: 0.0194 - acc: 0.9947 - val_loss: 0.1262 - val_acc: 0.9817\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 10s 163us/step - loss: 0.0204 - acc: 0.9946 - val_loss: 0.0989 - val_acc: 0.9839\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 10s 164us/step - loss: 0.0210 - acc: 0.9945 - val_loss: 0.1077 - val_acc: 0.9832\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 10s 163us/step - loss: 0.0179 - acc: 0.9955 - val_loss: 0.1233 - val_acc: 0.9828\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 10s 162us/step - loss: 0.0203 - acc: 0.9952 - val_loss: 0.1085 - val_acc: 0.9835\n",
            "Test loss: 0.10849166103507461\n",
            "Test accuracy: 0.9835\n",
            "CPU times: user 5min 27s, sys: 18.9 s, total: 5min 46s\n",
            "Wall time: 3min 22s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ax24-y0nZTQH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "結論\n",
        "\n",
        "CPU\n",
        "Test accuracy: 0.9826\n",
        "CPU times: user 5min 54s, sys: 17.5 s, total: 6min 12s\n",
        "Wall time: 3min 34s\n",
        "\n",
        "\n",
        "GPU\n",
        "Test accuracy: 0.9832\n",
        "CPU times: user 1min 10s, sys: 10.4 s, total: 1min 21s\n",
        "Wall time: 1min 8s\n",
        "\n",
        "\n",
        "\n",
        "TPU\n",
        "Test accuracy: 0.9835\n",
        "CPU times: user 5min 27s, sys: 18.9 s, total: 5min 46s\n",
        "Wall time: 3min 22s\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}